\documentclass[lettersize,journal]{IEEEtran}
\usepackage{amsmath,amsfonts}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{array}
\usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\usepackage{textcomp}
\usepackage{stfloats}
\usepackage{url}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{cite}
\usepackage{multirow}
\usepackage[utf8]{inputenc}
\hyphenation{op-tical net-works semi-conduc-tor IEEE-Xplore}

\begin{document}

\title{Framework for Assurance of Emergent Behaviour for use in Autonomous Robotic Swarms}

\author{Author1\_Name, Author2\_Name, ...AuthorN\_Name,
\thanks{Author1 and Author2 are with the Department of Dep1\_Name (email: , )}
\thanks{AuthorN is with the Department of Dep2\_Name (email: )}}
%\thanks{Manuscript received April 19, 2021; revised August 16, 2021.}}
% The paper headers
\markboth{Journal of \LaTeX\ Class Files,~Vol.~14, No.~8, August~2021}%
{Shell \MakeLowercase{\textit{et al.}}: A Sample Article Using IEEEtran.cls for IEEE Journals}

%\IEEEpubid{0000--0000/00\$00.00~\copyright~2021 IEEE}
% Remember, if you use this you must call \IEEEpubidadjcol in the second
% column for its text to clear the IEEEpubid mark.

\maketitle

\begin{abstract}
	Abstract of the paper.
\end{abstract}

\begin{IEEEkeywords}
	Assurance, swarm robotics, trustworthiness, safety, transparency, ethics, autonomous systems
	%Swarm Robotics, Acceptability and Trust, Autonomous Agents
\end{IEEEkeywords}

\section{Introduction}\label{introduction}
The main contribution of this paper is a novel framework for assurance of emergent behaviour for use in autonomous robotic swarms based on the AMLAS, SACE* and SOCA* guidance (* under consideration). We illustrate the framework using a public cloakroom case study. 

%\\\noindent\textbf{\textit{[Author General Guidelines: please write as a paper not as a Guidance like AMLAS; Please do not use AERoS word]}}\\


\section{Background and Related Work}\label{background-relatedwork}

\subsection{Background}\label{background}

\subsubsection{Specification Challenges and Standards}
%\newline With respect to swarms, the overall behaviours of a swarm are not explicitly engineered in the system, but they are an emergent consequence of the interaction of individual agents with each other and the environment.
%This emergent functionality poses a challenge for specification. 
%\newline How do you ensure safety or any other extra-functional property of a swarm where the swarm’s behaviour is an “emergent” consequence of the interaction of individual agents with each other and their environment?
%Swarm behaviours:
%\newline Aggregation 
%\newline Coherent ad-hoc network
%\newline Information retrieval
%\newline Taxis towards pick up and delivery areas of boxes
%\newline Obstacle avoidance
%\newline Object organization
%
%\textit{IEEE P7001} standard describes measurable, testable levels of transparency for autonomous systems so that they can be objectively assessed and levels of compliance determined\cite{IEEE-P7001}. 
%This standard outlines five stakeholder groups, and for each group it explains the structure of the normative definitions of levels of transparency. 
%\textit{IEEE P7001} can be applied to assess the transparency of an existing system using a process of System Transparency Assessment, or to specify transparency requirements for a system prior to its implementation (System Transparency Specification).
%The 5 stakeholders are end users, general public and bystanders, safety certification agencies and auditors, incident/accident investigators, expert advisors.
%
%In service robotics, ISO 13482 covers the hazards presented by the robots and devices for applications in non-industrial environments for providing services. 
%ISO 23482-1 and ISO 23482-2 standards extend ISO 13482 with guidance and methods that can be used to test personal care robots.
%On the other hand, in the industrial sector, ISO 10218-1 and ISO 10218-2 provide safety requirements for industrial robots and their integration.
%Meanwhile, ISO/TS 15066 provides safety requirements for collaborative industrial robot systems and work environment. 
%Although these industry standards focus on ensuring safety of robots at the individual robot level, they do not ensure safety or any other extra-functional property at the swarm level, which is a limitation.
%
%This Figure shows a categorization of robots by ISO. 
%Identifying which robot category the individual robots of the cloakroom is important because different legal and regulatory requirements apply to different robot categories.
%The “service robot” contains most robot categories, except industrial robot. 
%These are: household robots, medical robots and personal care robots.
%The individual robots of the cloakroom better fit into the “mobile servant robots” category, which is a type of personal care robot under service robots.
%A mobile servant robot is a personal care robot capable of travelling to perform serving tasks in interaction with humans, e.g. handling objects or exchanging information [ISO 13482:2014, 3.14].
\vspace{2mm}

\subsubsection{Robotic Swarms}
%\noindent Autonomous
%\\ \noindent Large Number of agents (10+)
%\\ \noindent Relatively incapable individuals
%\\ \noindent Restrained Homogeneity
%\\ \noindent Minimal communication capabilities (Decentralised)
\vspace{2mm}

\subsubsection{Case Study}

\vspace{2mm}
\noindent\textbf{\textit{\newline[Author Guidelines: Please use the cloakroom case study to illustrate the framework in Section III. If the examples in cloakroom case study are not sufficient, other swarm use cases listed below can be considered.]}}

\paragraph{\textbf{Cloakroom}\label{ex:cloakroom}}
The case study describes a public cloakroom where swarm of robots assist customers looking to deposit their jackets at an event \cite{Jones2020}. 
It describes cases where customers are depositing jackets, handing a jacket to a robot for storing, and retrieval of jackets back to the customer. 

\paragraph{Other Swarm Use Cases}
\textbf{\\Fault detection, diagnosis and recovery – Monitoring fires in a natural environment}. Fault detection model shall be trained to high level of accuracy. Thresholds for fault tolerance shall be set appropriately such that misclassification of a fault is a rare event. An agent experiencing minor faults shall not be immediately removed, should the fault not impact the task at hand. \\
\textbf{\noindent Social swarm – Brainstorming at an event}. Humans follow robots which cluster based on input. Minimise blocking paths of other humans and agents. Maintain situational awareness of humans and agents in the environment. Before the task, provide a clear explanation of the steps of the activity. Clear guidance during the task. Provide information about how the swarm/robot works.

\noindent See research paper ``Mutual shaping in swarm robotics: User studies in fire and rescue, storage organization, and bridge inspection" \cite{Carrillo-Zapata2020}.

\subsection{Related Work}\label{relatedwork}

\subsubsection{Assurance of Machine Learning in Autonomous Systems (AMLAS)}
%\cite{Hawkins2021}
\textit{Assurance of Machine Learning for use in Autonomous Systems (AMLAS)} provides guidance on how to systematically integrate safety assurance into the development of machine learning components based on offline supervised learning \cite{AMLAS2021}. 
AMLAS provides an explicit and structured safety case that the system is safe to operate in its intended context of use. 
AMLAS contains six stages, and the assurance activities are performed in parallel to the development of machine learning component. 
The process is iterative by design and feedback is used to update previous stages. 

\subsubsection{Safety Assurance of Autonomous Systems in Complex Environments (SACE)}
\cite{SACE2022}

\subsubsection{Societal Acceptability of Autonomous Systems (SOCA)}
\cite{Porter2022,McDermid2021}

\section{Framework}\label{framework}

\subsection{Overview of Framework} \label{framework-overview}
%Simple algorithms are executed by individuals.
%These simple behaviours performed by large numbers of agents build to emergent behaviours.
%The adaptivity provided by emergence requires assurance. 
%
%Safety Assurance Process based on AMLAS targeting robotic swarms:
%Emergent behaviour
%Failure conditions that the output of an individual robot or a robot in the neighbourhood makes to potential swarm-level hazards.
%
%Scope of current study:
%Looking purely at inherent swarm qualities and the adaptation that stems from these.
%Developing individual behaviours which when combined create an adaptive emergence.
%Machine/Reinforcement Learning should not be considered at this time.
%We may expand to ML/RL for individuals. (Application of AMLAS to individuals once AMLAS has been applied to the swarm)
\vspace{2mm}

%\subsection{Stage 1: EB Safety Assurance Scoping} \label{framework-stage1}
%\noindent \textbf{\textit{[Lead:  WP1]}}\\
%\noindent\textbf{\textit{[Author Guidelines: 900–1800 words / 1–2 pages (maximum); \\Format/structure: Describe adapted AMLAS activities, inputs and outputs using cloakroom case study examples. Activities: 1, 2; Inputs: A, B, C, D, F; Outputs: E, G]}}\\
%See Fig.~\ref{amlas-a-stage1}
%\begin{figure*}
%	\centering
%	\includegraphics[width=1.0\textwidth]{figures/amlas-a-stage1.png}
%	\caption{Adapted AMLAS emergent behaviour assurance scoping process (right).}
%	\label{amlas-a-stage1}
%\end{figure*}

\subsection{Stage 1: EB Safety Assurance Scoping} \label{framework-stage1}
In this study, we look at inherent swarm qualities and the adaptation that arises from these qualities. 
In a swarm, individual robots execute simple behaviours or algorithms, and these simple behaviours when performed by a large number of agents build to form \emph{emergent behaviours} (EB). 
%These simple behaviours performed by large numbers of agents build to emergent behaviours.
%For this, we will look into developing individual behaviours which when combined create an adaptive emergence. 
The adaptivity provided by this emergence requires us to provide \textit{assurance} (e.g. safety assurance). 
At present, our study does not consider machine learning components of individual agents. Instead, these will be considered as part of future work once AMLAS has been applied to the swarm.
%However, we may consider this later once AMLAS has been applied to the swarm.

The adapted Stage 1 contains two activities which are performed to define the safety assurance scope for the swarm (see Fig.~\ref{amlas-a-stage1}).  
As part of activity 2, the artefacts generated from Stage 1 are used to instantiate the EB safety assurance scoping argument pattern. \\

\noindent \textbf{Activity 1: Define the safety assurance scope for the EB description and expected output}

The required inputs to Stage 1 are the system safety requirements ([A]), the operating environment [B], the system description [C], and a description of the EB and expected output ([D]). 
Inputs A, B, C and D will be used to determine the safety requirements which are allocated to the swarm. 
The requirements defined in Stage 1 are independent of any EB technique or metric.
Instead, these requirements reflect the need for the swarm to perform safely with the system regardless of the deployed technology. 
The output of this activity is the safety requirements that are allocated to the swarm [E]. 
\begin{figure}[!t]
	\centering
	\includegraphics[width=0.5\textwidth]{figures/amlas-a-stage1-v2.png}
	\caption{Stage 1: Adapted AMLAS emergent behaviour assurance scoping process.}
	\label{amlas-a-stage1}
\end{figure}
\\

\noindent \textbf{Artefact A -- System safety requirements: }
The system safety assessment process generates the safety requirements of the swarm, which covers identification of hazards and risk analysis. 
As illustrated in Fig.~\ref{failure-events}, this can be shown in the form of concrete failure conditions from an individual robot propagating through the swarm neighbourhood, resulting in swarm-level hazards. 
Although this has been illustrated as a simplified linear chain of events, in reality this represents a complex sequence which can be difficult to distil into distinct events and cause.

With respect to hazard identification and risk analysis performed in our study, in the \textit{cloakroom} use case, a key hazard is the blocking of critical paths. 
This can result in humans or other agents in the swarm unable to travel to urgent locations in a safe manner. 

In the \textit{monitoring fires in a natural environment} use case, a considerable hazard can be presented should a critical fault go undetected. This can result in swarm operating with critically faulty agents resulting in the emergence of unsafe behaviour. The labelling of faults does, however, require caution and a level of trade off. Should a fault be misdiagnosed, for example, a minor fault being labelled as a critical fault (e.g. a minor reduction of the wheel speed labelled as full motor failure). The system or user may end up removing key agents from the swarm, resulting in significant loss of performance and efficacy in the swarms task.\\ 

\begin{figure}[!t]
	\centering
	\includegraphics[width=0.5\textwidth]{figures/stage1-failureevents.png}
	\caption{Failure conditions in a swarm [adapted from DO-178C, AMLAS].}
	\label{failure-events}
\end{figure}

\noindent \textbf{Artefact B -- Environment description: }
As in AMLAS guidance, when allocating safety requirements to the swarm, it is essential to consider the system environment, which is represented by Artefact B. 
Based on the different use cases considered in our study, we can provide a description of their environments as follows.
\begin{itemize}
	\item \textit{A swarm of robotic agents collecting and delivering jackets, stored in small box-like containers within a cloakroom}. Agents are required to navigate a public space between collection and delivery points of jackets. Agents use local communication, perception, and data to form an emergent system of navigation that allows them to easily traverse the public space between jacket collection and delivery points.
	\item \textit{A swarm of UAVs monitoring wildfire risks in a natural environment}. Here, agents will be required to stay within communication range of each other, effectively covering the search area and accurately detecting risks of fire.
	\item \textit{Social swarm – brainstorming at an event}. Humans input their opinions on agents which then cluster based on the input. [Humans follow the agent they interacted with and user groups emerge in the process.]\\
\end{itemize}

\noindent \textbf{Artefact C -- System description: }
To describe our logistics use case, we must consider three inputs: sensor availability, neighbourhood data, and swarm parameters. 

In this instance, the \textit{sensors} available to agents might be: cameras (multiple), Bluetooth communication devices, and light detection and ranging systems (see Fig.~\ref{system-description}). 

The neighbourhood data of the swarm can be specified through the communication systems available to agents, in this case Bluetooth. Through the use of the short range communication available to them, we can assume agents have access to neighbourhood data such as: the approximate position of local agents, current behaviour statuses, an approximate history of box movement, and the amount of time deployed. 

As for the swarm level parameters, we can consider options specified by a user i.e. the number of agents deployed, the maximum speed of agents, and the number of agents allowed to be active at a time.

Once we have defined these three inputs they are fed to the individual agents to instruct their behaviour. This behaviour, once enacted by the multiple agents, produces a swarm level emergence as the individuals interact with one another and their environment.

\begin{figure}
	\centering
	\includegraphics[width=0.4\textwidth]{figures/stage1-systema.png}
	\caption{System description.}
	\label{system-description}
\end{figure}

\noindent \textbf{Artefact D -- EB description and expected output: }
%This artefact describes the role and scope of the component within the system of which it is part, and the interfaces to which it is exposed.
By expected output here, we mean the gains that can arise from the system by deploying multiple agents.
%Let us consider the type and configuration of the emergent behaviour. 
For our logistics use case, the output is a collaborative system capable of collecting, sorting and redelivering jackets in a public setting. 

To achieved this output, the emergent behaviour of the system needs to be manually engineered by a swarm engineer with consideration to the available sub-behaviours within an agent and the constraints outlined in the system description.\\
%

\noindent \textbf{Activity 2: Instantiate the EB assurance scoping argument pattern}

\noindent \textbf{Artefact F -- EB Safety assurance scoping argument pattern: }
The argument pattern relating to this stage is shown in Fig.~\ref{stage1-ap}. 
\begin{figure}
	\centering
	\includegraphics[width=0.4\textwidth]{figures/stage1-argumentpattern.png}
	\caption{EB Safety assurance scoping argument pattern.}
	\label{stage1-ap}
\end{figure}

\subsection{Stage 2: EB Safety Requirements Assurance} \label{framework-stage2}
%\noindent \textbf{\textit{[Lead:  WP1; Other: WP2, WP3]}}\\ 
%\noindent\textbf{\textit{[Author Guidelines: total 7 pages (maximum); \\Format/structure: Describe adapted AMLAS activities, inputs and outputs using cloakroom case study examples. \\
		%\noindent WP1 = (Activities: 3, 4, 5; Inputs: E, I; Outputs: H, J, K: 2700 words / 3 pages maximum))\\
		%\noindent WP2 = (List of Ethical Requirements and Description: 1800 words / 2 pages maximum)\\
		%\noindent WP3 = (List of Socio-Technical/Regulatory Requirements and Description: 1800 words / 2 pages maximum)]
		%}}\\
As in AMLAS, adapted Stage 2 contains three activities (Fig.~\ref{amlas-a-stage2}), which are performed to provide assurance in EB safety requirements for the swarm. 
In activity 5, the artefacts generated are used to instantiate the EB safety requirements assurance argument pattern. 
The scope of this stage is limited to the EB model of the swarm.\\

\begin{figure}[!t]
	\centering
	\includegraphics[width=0.5\textwidth]{figures/amlas-a-stage2-v2.png}
	\caption{Stage 2: Adapted AMLAS emergent behaviour safety requirements assurance process.}
	\label{amlas-a-stage2}
\end{figure}

\noindent \textbf{Activity 3: Develop EB safety requirements}

The required input to Activity 3 in Stage 2 is the safety requirements allocated to the swarm ([E]).
We define EB safety requirements to control the risk of the swarm to system-level hazards by taking into account of the defined system architecture and operating environment. 

As in AMLAS, although there can be a wide range of requirements for the swarm like scalability, security and interpretability, the EB safety requirements need to be limited to the ones that have an impact on the operational safety of the system. 
Other types of requirements (e.g. security, scalability) need to be defined as EB safety requirements, only if their behaviours or underlying constraints have an influence on the safety-criticality of the swarm's output.  

The AMLAS guidance prescribes two types of requirements for ML components: performance and robustness. 
In the swarm context, we consider four types of requirements: \emph{performance}, \emph{adaptability}, \emph{human safety}, and \emph{environment}.
Robustness in the swarm context is a more broad notion, thus we introduce adaptability and environment sub-categories. 
In AMLAS, one key approach when defining robustness requirements is to consider the dimensions of variation which exist in the input space. In the swarms context, this can be variation in the simulation space instead of the input space. 

We consider several performance safety metrics under the four requirements categories: 
(i) performance: low impact and high impact collisions; 
(ii) adaptability: percentage of swarm stationary outside of the delivery site, number of stationary agents, time since last agent moved; 
(iii) human-safety: velocity or average velocity of agents, swarm size, rate of human encountered, proximity to humans;
(iv) environment: sum of objects/$m^2$.

For the performance, adaptability and human-safety requirements categories, we formulate requirements under three sub-categories: \emph{faultless operations}, \emph{failure modes (graceful degradation)}, and \emph{worst case}. 
In the conventional AMLAS framework, the level of faults one expect in a single ML system is low. 
However, in a swarm system, we expect it to have more faults, as there are more agents which are more difficult to monitor. 
As for \emph{graceful degradation}, we mean what is the acceptable level of faults, their impact, and how the system should react when those faults are introduced. 
Thirdly, we consider requirements for \emph{worst case}, which account for the least acceptable impact the system should experience and means of avoiding it. \\

\noindent \textbf{Activity 4: Validate EB safety requirements}

The required input to Activity 4 in Stage 2 is the safety requirements allocated to the swarm ([E]). 
As suggested in AMLAS guidance, we use reviews and simulations to validate the EB safety requirements.\\

\textbf{Reviews:} the requirements derived for the cloakroom were also reviewed by a safety-critical systems engineering expert to ensure that the specified EB safety requirements for the swarm will deliver its intended safe operation. This expert has a wide experience in topics related to aerospace, defence and transportation; and safety of autonomous systems. Previously, this expert had reviewed the CovidSim modelling, which was instrumental in settling the UK lock-down policy. 

\textbf{Simulation: }We have validated several EB safety requirements (all performance, adaptability, and environment requirements except requirement RQ4.5) of the cloakroom system using a 3D simulator (Gazebo). This simulation is an exact replication of the 4m x 4m lab environment (see Fig.~\ref{3Dsim}). \\

\begin{figure}[!t]
	\centering
	\includegraphics[width=0.5\textwidth]{figures/3Dsim.png}
	\caption{3D simulation created to validate several EB safety requirements of the cloakroom.}
	\label{3Dsim}
\end{figure}

\noindent \textbf{Stage 2 Requirements (Output H)}\\
\noindent \textbf{Cloakroom: Performance Requirements (see Table~\ref{tab:perormance}):}
\begin{table}[!t]
	\centering
	\begin{tabular}{|p{7mm}|p{72mm}|}
		\hline
		& \textbf{Requirements for Faultless Operations} \\
		\hline
		RQ1.1 & The swarm \emph{shall} experience \textbf{$<$ 1 low impact (V $<$ 0.5m/s)} collisions across \textbf{1000} seconds of faultless operation. \\ 
		\hline
		RQ1.2 & The swarm \emph{shall} experience \textbf{$<$ 1 high impact (V $>$ 0.5m/s)} collisions across \textbf{a day} of faultless operation. \\ 
		\hline
		& \textbf{Requirements for Failure Modes (Graceful Degradation): } \\
		\hline
		RQ1.3 & The swarm \emph{shall} experience \textbf{$<$ 10\%} increase in \textbf{low impact} collisions across \textbf{1000} seconds of operation with \textbf{10\% injection} of \textbf{full communication fault} to the swarm. \\
		\hline
		RQ1.4 & The swarm \emph{shall} experience \textbf{$<$ 0.1\%} increase in \textbf{high impact} collisions across \textbf{a days} operation with \textbf{10\% injection} of \textbf{full communication fault} to the swarm.\\ 
		\hline
		RQ1.5 & The swarm \emph{shall} experience \textbf{$<$ 10\%} increase in \textbf{low impact} collisions across \textbf{1000} seconds of operation with \textbf{50\% injection} of \textbf{half-of-wheels motor faults} to the swarm.\\
		\hline
		RQ1.6 & The swarm \emph{shall} experience \textbf{$<$ 0.1\%} increase in \textbf{high impact} collisions across \textbf{a days} operation with \textbf{50\% injection} of \textbf{half-of-wheels motor faults} to the swarm.	\\	
		\hline
		& \textbf{Requirements for Worst Case: } \\
		\hline
		RQ1.7 & The swarm \emph{shall} experience \textbf{$<$ 2 low impact (V $<$ 0.5m/s)} collisions across \textbf{1000} seconds of faulty operation. \\			\hline	
		RQ1.8 & The swarm \emph{shall} experience \textbf{$<$ 2 high impact (V $>$ 0.5m/s)} collisions across \textbf{a day} of faulty operation.  \\		[1ex] 		
		\hline
	\end{tabular}
	\caption{\label{tab:perormance}Performance requirements for the cloakroom.}
\end{table}    

\noindent \textbf{Cloakroom: Adaptability Requirements (see Table~\ref{tab:adaptability}):}
\begin{table}[!h]
	\centering
	\begin{tabular}{|p{7mm}|p{72mm}|}
		\hline
		& \textbf{Requirements for Faultless Operations} \\
		\hline
		RQ2.1 & The Swarm \emph{shall} have \textbf{$<$ 10\%} of its agents \textbf{stationary*} outside of the \textbf{delivery site} at a given time.
		*Assumption: Agents are considered stationary once they have not moved for $>$ 10 seconds.
		\\ 
		\hline
		RQ2.2 & All agents of the swarm \emph{shall} move at least every \textbf{100 seconds} if outside of the \textbf{delivery site}. \\ 
		\hline
		& \textbf{Requirements for Failure Modes (Graceful Degradation): } \\
		\hline
		RQ2.3 & The swarm \emph{shall} experience $<$ 10\% increase in \textbf{number of stationary agents} at any given time with 50\% injection of half-of-wheels motor faults to the swarm. \\
		\hline
		RQ2.4 & The swarm agents \emph{shall} experience $<$ 10\% increase in \textbf{stationary time} with 50\% injection of half-of-wheels motor faults to the swarm.\\ 
		\hline
		RQ2.5 & The swarm \emph{shall} experience $<$ 10\% increase in \textbf{number of stationary agents} at any given time \textbf{10\% injection} of \textbf{full communication fault} to the swarm.\\
		\hline
		RQ2.6 & The swarm agents \emph{shall} experience $<$ 10\% increase in \textbf{stationary time 10\% injection} of \textbf{full communication fault} to the swarm. \\	
		\hline
		& \textbf{Requirements for Worst Case: } \\
		\hline
		RQ2.7 & The Swarm \emph{shall} have \textbf{$<$ 20\%} of its agents \textbf{stationary*} outside of the \textbf{delivery site} at a given time.
		*Assumption: Agents are considered stationary once they have not moved for $>$ 10 seconds. \\			\hline	
		RQ2.8 & All agents of the swarm \emph{shall} move at least every \textbf{200 seconds} if outside of the \textbf{delivery site}.\\		[1ex] 		
		\hline
	\end{tabular}
	\caption{\label{tab:adaptability}Adaptability requirements for the cloakroom.}
\end{table}   
\noindent Metric: Swarm waiting time/time-in-area

\noindent \textbf{Cloakroom: Human Safety Requirements (see Table~\ref{tab:human-s}):}
\begin{table}[!h]
	\centering
	\begin{tabular}{|p{9mm}|p{72mm}|}
		\hline
		& \textbf{Requirements for Faultless Operations} \\
		\hline
		RQ3.1 & The agents in the swarm \emph{shall} travel at speeds of less than \textbf{0.5m/s} when within \textbf{2m} distance of a \textbf{trained human*.}
		\\ 
		\hline
		RQ3.2 & The agents in the swarm \emph{shall} travel at speeds of less than \textbf{0.25m/s} when within \textbf{3m} distance of a \textbf{member of the public}.
		\\ 
		\hline
		RQ3.3 & The agents in the swarm \emph{shall} only come within \textbf{2m} distance of a \textbf{human $<$ 10} times collectively across \textbf{1000 seconds} of \textbf{faultless} operations.
		\\ 
		\hline
		RQ3.4 & The swarm \emph{shall} only allow \textbf{$<$ 5 agents} to request intervention from a \textbf{trained human*} at a given time
		\\ 
		\hline
		RQ3.5 & A Trained human \emph{shall} monitor 5-20 agents at a given time.
		\\ 
		\hline
		RQ3.6 & The swarm \emph{shall} only allow \textbf{1 agent} to request input from a \textbf{member of the public} at a given time.
		\\ 
		\hline
		RQ3.7 & A member of the public \emph{shall} receive $<$ 5 agents of swarm information at a given time.
		\\ 
		\hline
		& \textbf{Requirements for Failure Modes: } \\
		\hline
		RQ3.8 & The swarm \emph{shall} experience \textbf{$<$ 10\%} increase in \textbf{human encounters} across 1000 seconds of operation with \textbf{10\% injection} of \textbf{full communication fault} to the swarm. \\
		\hline
		RQ3.9 & The swarm \emph{shall} experience \textbf{$<$ 10\%} increase in \textbf{human encounters }across 1000 seconds of operation with \textbf{50\% injection} of \textbf{half-of-wheels motor faults} to the swarm.\\ 
		\hline
		& \textbf{Requirements for Worst Case: } \\
		\hline
		RQ3.10 & The agents in the swarm \emph{shall} only come within \textbf{2m} distance of a \textbf{human $<$ 20} times collectively across \textbf{1000 seconds} of \textbf{faulty} operations.
		\\		[1ex] 		
		\hline
	\end{tabular}
	\caption{\label{tab:human-s}Human safety requirements for the cloakroom.}
\end{table}   
\noindent *Trained human in this case refers to workers within the case study setting. We assume that this individual has received relevant training \& experience in the use of the swarm system.\\

\noindent \textbf{Cloakroom: Environmental Specification (see Table~\ref{tab:environment}):}
\begin{table}[!h]
	\centering
	\begin{tabular}{|p{7mm}|p{72mm}|}
		\hline
		RQ4.1 & The swarm \emph{shall} perform as required in environmental density levels 0-4 \textbf{p$_o$* of objects (sum of boxes and agents)} in the environment.
		\\ 
		\hline
		RQ4.2 & The swarm \emph{shall} perform as required when floor incline is 0-20 degrees.
		\\ 
		\hline
		RQ4.3 & The swarm \emph{shall} perform as required in a dry environment.
		\\ 
		\hline
		RQ4.4 & The swarm \emph{shall} perform as required in smooth-floored environments with step increases no greater than 0.5cm.
		\\ 
		\hline
		RQ4.5 & The swarm \emph{shall} only operate in environments where humans have devices that identify the human’s whereabouts to the swarm agents.
		\\		[1ex] 		
		\hline
	\end{tabular}
	\caption{\label{tab:environment}Environment requirements for the cloakroom.}
\end{table}   
\noindent *p$_o$ = sum of objects  / m$^2$

\begin{table*}
	\centering
	\begin{tabular}{|l| l| l| l| l| l|} %{|*{18}{c|}}  % repeats {c|} 18 times 
		\hline
		\multicolumn{6}{|p{15cm}|}{\textbf{System: Cloakroom System} \newline \textbf{Specifier: Safety Engineer} \newline \textbf{Date: 03 October 2022} \newline The cloakroom system requires a high degree of transparency for the trained workers, but with less transparency for the customers, due to concerns of criminals exploiting it.} \\ \hline
		\multirow{2}{11cm}{\textbf{IEEE Std 7001-2021 subclause \newline (C = cumulative, NC = non cumulative)}} & \multicolumn{5}{c|}{\textbf{Levels}} \\ \cline{2-6}
		& 1 & 2 & 3 & 4 & 5 \\ \hline
		5.1.1 Users (NC) & $X^*$ & $X^*$ & & & \\ & $X^{**}$ & $X^{**}$ & $X^{**}$ & & \\ \hline
		\multicolumn{6}{|p{15cm}|}{Note- Two categories of users are defined as follows: \newline
			* \textit{Customers} who are non-expert users.\newline %Transparency is comparatively more important to this category compared to trained staff.
			** \textit{Trained staff} are expert or super users of the cloakroom. These can be deployers and administrators of the swarm, such as site managers. They require a medium level of understanding of how the swarm works, including the ability to ask an agent to explain its decisions, to predict the system's behaviour in a given situation and repair simple faults of agents.} \\  \hline
		5.1.2 General public and bystanders (NC) & X & X & & & \\ \hline
		\multicolumn{6}{|p{15cm}|}{NOTE—The individual robots in the swarm are clearly identified as robots, with warnings; they are fitted with cameras for navigation, with limited views so that they do not collect personal data. This group is only indirectly affected by the system. }\\ \hline
		5.2.1 Validation and certification agencies (C) & X & X & & & \\ \hline
		\multicolumn{6}{|p{15cm}|}{NOTE—Evidence of validation and certification to a lower degree is sufficient such as equipped with a data-logging system, given the less-sensitivity of the system.}\\ \hline
		5.2.2 Incident investigators (C) & X & X & & & \\ \hline
		\multicolumn{6}{|p{15cm}|}{NOTE—The cloakroom system must log all events securely to support incident investigations, noting that incident investigation may be triggered by a customer, or a watchdog raising concerns about the functions of the swarm. The agents in the swarm are equipped with a data logging system that records high level decisions (no personal data will be recorded). Levels 3--5 are not considered essential, as the agents in the swarm will only require a limited number of behaviours (with no learning).  }\\ \hline
		5.2.3 Expert advisors in administrative actions or litigation (NC) & X & & & & \\ \hline
		\multicolumn{6}{|p{15cm}|}{NOTE—The company should take into account ISO 9001 accreditation or equivalent for the swarm.}\\ \hline
	\end{tabular}
	\caption{\label{tab:transparency}System transparency specification for the cloakroom.}
\end{table*}

\subsubsection{System Transparency Specification for the Cloakroom}
In this section, we show how IEEE P7001 standard can be applied to specify transparency requirements for the Cloakroom prior to its implementation, which is known as a process of \textit{System Transparency Specification} (STS) \cite{IEEE-P7001}. IEEE P7001 describes a set of normative requirements on transparency and explainability, which must be satisfied to be labelled as compliant. % cite both


%\paragraph{System Transparency Specification for the Cloakroom}
A company that organizes bespoke events with 50 to 10000 attendees is looking to automate their cloakroom by deploying a swarm of robots to assist attendees (customers) to deposit, store and deliver their belongings (e.g. jackets) \cite{Jones2020}. % cloakroom paper 
%Mindful of the safety, operational and regulatory requirements of the healthcare sector
The system must prioritize public safety, and the company decides to use this standard on transparency as a draft specification for their engineers to more transparently communicate the decision-making processes of their automated cloakroom. %swarm system. 
The score sheet summarizing the outcomes of the assessment is shown in Table~\ref{tab:transparency}. \\

\subsubsection
\textbf{\textbf{Using the Structural, Organisational, Technological, Epistemic, and Cultural (SOTEC) framework for a sociotechnical requirements analysis of autonomous robotic swarms}}
\\
This section outlines Macrae’s (2021) Structural, Organisational, Technological, Epistemic, and Cultural (SOTEC) framework of sociotechnical risk in Autonomous and Intelligent systems (AIS) and discusses its regulatory implications for autonomous swarms in a cloakroom scenario. The SOTEC framework proposes that risk and failure in AIS be understood in terms of five broad sociotechnical categories, each corresponding to different organisational, contextual, and human factors that might inform AIS safety requirements.
\\ 

The spotlight on sociotechnical sources of risk in AIS throughout section one provides a crucial launching point for the identification of sociotechnical requirements. The exact meaning of sociotechnical requirements is the topic of the second section. Viewing requirement analysis from a sociotechnical perspective allows us to move away from a purely technical conception of requirements, and helps us design autonomous systems that better fit the organisation and operators’ work in which safety considerations are meaningful within the wider system and operational context. Based on these considerations, the section illustrates the crafting of five dimensions of regulatory requirements for autonomous robotic swarms as a safety assurance mechanism. 

.\\
\textit{1. The relevance of the SOTEC framework for sociotechnical requirements}
\\
Most pre-existing work on safety assurance in AIS has focused on developing technical aspects of assurance (Brundage et al., 2020). The work has proven challenging (e.g., Karvonen et al., 2020; Thieme et al., 2021; Hernandez et al., 2021). The causes of some highly visible AIS failures were unforeseen, and therefore untested and unmanaged. The latent problem with Uber’s self-driving computer vision system, which led to the first autonomous vehicle fatality in 2018 (Niedermeyer, 2019), is one example. We might also look to the ‘object classification’ failures in the STM Kargu-2 lethal autonomous weapons system, which may have led it to hunt down and remotely engage retreating Libyan soldiers in March 2020 (Nasu, 2021). Or to a fault in an AI designed for diagnosing skin cancer, which misled clinical experts in 2019 (Tschandl et al., 2020). 

Such failures have eluded experts, we might say, because their causes are rarely reducible to technical criteria alone. There is always a degree to which those causes lie in the wider ‘sociotechnical’ dimensions of autonomous and intelligent systems: the fact that AIS are “… designed, developed, built, deployed, maintained, supervised, operated, and governed by people,” as Macrae (2021: 3) puts it, and that those people operate within complex social, cultural, and organisational processes” (see also: Pettersen Gould, 2021; Reason, 1997). So it is, Macrae (2021) argues, that researchers developing assurance tools for autonomous systems should consider sociotechnical sources of risk and failure. To this end, he invokes the 2018 Uber accident to propose and illustrate five intersecting dimensions along which such risks might be understood. He labels these: Structural; Organisational; Technological; Epistemic, and Cultural (‘SOTEC’). We will outline each category briefly below.
. \\

\textbf{Structural} sources of risk arise from the way different human and nonhuman elements in a system interact. In Macrae’s telling, for example, Uber’s perception software failed to correctly classify a pedestrian crossing the road, which then prevented the prediction system from calculating a predicted path for the hazard, which then prevented the motion planning system to apply emergency brakes (Macrae, 2021: 8). 

\textbf{Organisational} sources of risk emerge when organisational structures — such as rules and expectations — are insensitive to the vagaries of real human behavior. In the Uber case, for example, Macrae (2021: 9) points to weaknesses in the way the human safety driver was supported and monitored, and to unrealistic presumptions about their performance: arguing that such factors had been neglected by regulators. 

\textbf{Technological} sources of risk arise from the specific capabilities and constraints inscribed into and produced by the system itself. Macrae (2021: 10), for example, finds that Uber’s self-driving software was designed in ways that inadvertently hid the presence of potential hazards from safety drivers, and often ignored them in order to curb excessive breaking and smooth the vehicle’s motion. 

\textbf{Epistemic} sources of risk arise from the ways that human knowledge is often incomplete, wrong, or out of date: creating pockets of ignorance that hide unexpected hazards. Macrae (2021: 12), for instance, finds that limitations in Uber engineers’ capacity to analyse and review operational events (such as ‘near-misses’) stymied their ability to gather and utilize data. 

\textbf{Cultural} sources of risk arise from collective values, beliefs, norms and practices, which surround and inevitably shape AIS design and operation. Macrae points to a number of such factors at work in the Uber accident. Some staff felt disempowered, for example, and were discouraged from raising safety concerns or challenging assumptions.

.\\The SOTEC framework is a relatively blunt instrument, but offers a useful tool for stimulating awareness and discussion of non-technical issues in requirements engineering. In the context of robotic swarms, for example, it encourages critical reflection on the constraints of their operational environment, and on the needs and expectations of the people with whom they will interact. Most generally, it highlights a range of ‘sociotechnical’ concerns that could be useful in framing requirements for autonomous systems. The next section explores how this might work in practice.

\


2. Sociotechnical Requirements for autonomous robotic swarms

As discussed, some of the most vexing difficulties of framing requirements for AIS are social rather than purely technical (Jirotka and Goguen, 1994). AIS are built for people and by people; they exist in a human context and serve a human purpose. It is important that requirements consider the implications of this (Goguen, 1993). Requirements engineering can never be an entirely ‘technical’ process, because its very nature is to try and understand the users’ needs or objectives, and reconcile them with technical possibilities (Goguen, 1993; Jirotka and Goguen, 1994; Reddy et al., 2003). 

To uncover sociotechnical requirements, we need to closely examine the work that the system will support in addition to the technology itself (Jirotka and Goguen, 1994). This implies simultaneously acting on a whole range of work practices in the human-swarm work environment, including the monitoring of garment collection from humans, the monitoring of garment delivery to the cloakroom, and the monitoring of garment storage in small-box like containers within a cloakroom. The SOTEC framework, split across five tables highlights that humans work within, and are shaped by complex social, organisational, technological, epistemic and cultural processes. Thus, an AIS-based system must be designed in consideration of risks that emerge from these five intersecting domains in the context of cloakroom work. 



\subsection{Stage 3: Data Management} \label{framework-stage3}
% \noindent \textbf{\textit{[Lead:  WP5]}}\\ 
% \noindent\textbf{\textit{Author Guidelines: 900–1800 words / 1–2 pages (maximum); \\Format/structure: Describe adapted AMLAS activities, inputs and outputs using cloakroom case study examples. Activities: 6, 7, 8; Inputs: H; Outputs: L0, L1, M, N, O, P, Q, S}}\\
% See Fig.~\ref{amlas-a-stage3}
% \begin{figure*}
% 	\centering
% 	\includegraphics[width=1.0\textwidth]{figures/amlas-a-stage3.png}
% 	\caption{Adapted AMLAS data management process.}
% 	\label{amlas-a-stage3}
% \end{figure*}

In the case of designing emergent behaviours data plays a vital role, though one that differs from the machine learning applications AMLAS was initially designed for. In order to address this difference, the following activities and outputs have been adjusted to take into account the swarm behavioural design process and the added complexities that come with multiple agents interacting with one another.

\begin{figure*}
	\centering
	\includegraphics[width=1.0\textwidth]{figures/Stage3_DM.png}
	\caption{Adapted AMLAS data management process.}
	\label{amlas-a-stage3}
\end{figure*}

\subsubsection*{Activity 6. Define Data Requirements}

% AMLAS - This activity requires as input the ML safety requirements ([H]) as described in Stage 2 and, from these requirements, data requirements ([L]) shall be generated. Of particular interest in the development of data requirements are those safety requirements which pertain to the description of the system environment.

In our adaptation of activity 6 we take the emergent behaviour safety requirements [H] outlined in Stage 2 as an input. These safety requirements guide the data requirements in this activity, feeding into the data specification that we outline here. Unlike the original AMLAS framework, we have split the data requirement [L] into two multi-agent focused requirements: [L.0] data type requirements and [L.1] data availability constraints.

\paragraph*{[L.0] Data Type Requirements}

This elements focus on the relevance, completeness, accuracy, and balance of the information that will be used to construct the swarm behaviour and will be subsequently used to test the emergent behaviour of the system prior to its deployment.

The relevance of the data used in the development of the emergent behaviour specifies the extent to which the test environment must match the intended operating domain into which the model is to be deployed. Examples of requirements relating to relevance are shown in Table \ref{tab:L0_relevance}.

\begin{table}[h]
    \centering
    \begin{tabular}{p{1cm} p{6cm}}
        \textbf{ID} & \textbf{Example} \\
        \hline
        RQ 5.1 & All simulations shall include environments with different ranges of incline between 0-20\textdegree.\\
        \hline
        RQ 5.2 & All simulations shall be conducted in a dry environment.\\
        \hline
        RQ 5.3 & All simulations shall include floors with step increases that are $\leq$ 0.5 cm.\\
    \end{tabular}
    \caption{Relevance requirement examples for output [L.0].}
    \label{tab:L0_relevance}
\end{table}

The completeness of the data specifies the conditions under which we test the behaviour algorithm i.e. the volume of experiments or tests that will be run, the variety of tests executed, and the diversity of environments expected to be used in the testing process. Requirements examples relating to completeness are shown in Table \ref{tab:L0_completeness}.

\begin{table}[h]
    \centering
    \begin{tabular}{p{1cm} p{6cm}}
        \textbf{ID} & \textbf{Example} \\
        \hline
        RQ 6.1 & All simulations shall be repeated to include fault injections representative of full communication faults.\\
        \hline
        RQ 6.2 & All simulations shall be repeated a sufficient number of times to ensure results are representative of typical use.\\
        \hline
        RQ 6.3 & All simulations shall be repeated in multiple environments representative of those expected in real-world use of the system.\\
        \hline
        RQ 6.4 & All simulations shall include sufficient range of robot density levels within the scope of the operational domain.\\ 
    \end{tabular}
    \caption{Completeness requirement examples for output [L.0].}
    \label{tab:L0_completeness}
\end{table}

Accuracy in this context relates to the parameters defining the performance of the swarm systems primary function. For example, what constitutes a delivery in a logistics scenario, or under what conditions would an area be considered explored in a surveying mission. Table \ref{tab:L0_accuracy} shows some data requirement examples relating to accuracy.

\begin{table}[h]
    \centering
    \begin{tabular}{p{1cm} p{6cm}}
        \textbf{ID} & \textbf{Example} \\
        \hline
        RQ 7.1 & All boxes shall only be considered ‘delivered’, if all four of the boxes’ feet are positioned within the delivery zone.\\
        \hline
        RQ 7.2 & All boxes shall only be considered ‘delivered’, once they are no longer in direct contact with a swarm agent.\\
    \end{tabular}
    \caption{Accuracy requirement examples for output [L.0].}
    \label{tab:L0_accuracy}
\end{table}

Balance, outside of a machine learning use case, refers the balance of the trials executed in the testing process of the emergent behaviour algorithm. By considering balance, we expect the number of tests conducted for individual failure modes or environment types to be justified, ensuring that there is not an unrealistic bias in testing towards a particular scenario. Some examples of data requirements relating to balance are listed in \ref{tab:L0_balance}.

\begin{table}[h]
    \centering
    \begin{tabular}{p{1cm} p{6cm}}
        \textbf{ID} & \textbf{Example} \\
        \hline
        RQ 8.1 & All simulations shall be repeated so as to obtain representative evaluations for each possible mode of failure (defined under performance, adaptability and human-safety requirements in Stage 2).\\
        \hline
        RQ 8.2 & All simulations shall be repeated equally across all test environments.\\
        \hline
    \end{tabular}
    \caption{Balance requirement examples for output [L.0].}
    \label{tab:L0_balance}
\end{table}

%In Table \ref{tab:L0} we list each of the requirement focuses considered in this output and provide respective examples of swarm data requirements.

% \begin{table}[H]
%     \centering
%     \begin{tabular}{p{2cm} p{6cm}}
%         \textbf{Requirement} & \textbf{Example} \\
%         \hline
%         Relevance & All simulations shall include environments with different ranges of incline between 0-20\textdegree.\\
%         \hline
%         & All simulations shall be conducted in a dry environment.\\
%         \hline
%         & All simulations shall include floors with step increases that are \leq 0.5 cm.\\
%         \hline
%         Completeness & All simulations shall be repeated to include fault injections representative of full communication faults.\\
%         \hline
%         & All simulations shall be repeated a sufficient number of times to ensure results are representative of typical use.\\
%         \hline
%         & All simulations shall be repeated in multiple environments representative of those expected in real-world use of the system.\\
%         \hline
%         & All simulations shall include sufficient range of robot density levels within the scope of the operational domain.\\
%         \hline
%         Accuracy & All boxes shall only be considered ‘delivered’, if all four of the boxes’ feet are positioned within the delivery zone.\\
%         \hline
%         & All boxes shall only be considered ‘delivered’, once they are no longer in direct contact with a swarm agent.\\
%         \hline
%         Balance & All simulations shall be repeated equally across all test environments.\\
%         \hline
%         & All simulations shall be repeated equally across all test environments.\\
%     \end{tabular}
%     \caption{Requirement focuses for output [L.0] with representative examples from the cloakroom use case.}
%     \label{tab:L0}
% \end{table}

\paragraph*{[L.1] Data Availability Constraints}

With the introduction of multiple agents comes the issue of data availability. Distributed communication is a key feature found in emergent systems. As such, it is crucial to define how much information each agent is expected to hold, how easily data may transfer between agents, and across what range agents should be able to transfer information between one another. We present a list of feasible constrains with representative examples in Table \ref{tab:constraints}.

\begin{table}[H]
    \centering
    \begin{tabular}{p{2cm} p{6cm}}
         \textbf{Constraint Type} & \textbf{Example}  \\
         \hline
         Storage capacity & The swarm agents shall have a maximum of 2 GB of information stored on board at any point in time. \\
         \hline
         Available sensors & The swarm agents shall only have access to environmental data deemed feasibly collectable by infrared sensors positioned radially every 30 degrees. \\
         \hline
         Communications Range & The swarm agents shall only have access to other agent data when within communications range of 5 meters. \\
         \hline
         Operator feedback & The swarm agents shall only share information with non-agent’s (e.g. operator terminal) when within communications range of 5 meters.
    \end{tabular}
    \caption{Swarm data constraints for output [L.1] with representative examples from the cloakroom use case.}
    \label{tab:constraints}
\end{table}

\paragraph*{[M] Data Requirements Justification Report}

This report remains mainly unchanged from the traditional AMLAS framework. This report acts as an assessment of the data requirements, providing analysis and explanation for how the requirements and constraints (outlined in [L.0] and [L.1]) address the emergent behaviour safety requirements specified in [H].

\subsubsection*{Activity 7. Define Swarm Evaluation Requirements}

Taking the outputs [L.0] and [L.1] from the activity 6, the evaluation requirements take into account how the emergent behaviour of the swarm will be assessed, specifying the testing environment and the metrics comprising the test results.  

\paragraph*{[N] Test Environment}

This output takes into consideration the requirements specified in activity 6 and defines the environment in which the emergent behaviour will be tested. In most cases this will be multiple simulation environments featuring diverse sets of terrain, environmental conditions and obstacle configurations. There may also be instances in which this test environment is specified as a physical environment operating under laboratory conditions, with a hardware systems acting as a test bed to observe designed behaviours.

\paragraph*{[O] Swarm Performance Metrics}

The performance metrics specified in this activity are used to quantify how well the system is performing. While there may be multiple performance metrics, these metrics should be defined with respect to the primary function of the swarm system. Metrics that might feature in this output could include: the delivery rate in a logistics scenario, rate of area coverage as well as the efficiency of said coverage in an exploration task, or the response time in a disaster scenario.

\paragraph*{[P] Verification Metric}

These metrics should be derived from the safety requirements [H] specified in Stage 2. These metrics are intended to be used as the criteria for success within the verification process. Examples of these metrics and their related safety requirements might include: Swarm density, used in verifying environmental safety specifications such as RQ 4.1, maximum collision force experienced by agents, which could be used to verify that the swarm meets safety performance requirements such as RQ 1.1 and RQ 1.2, or current speed of all agents, a metric relating directly to the human safety requirements RQ 3.1 and RQ 3.2.

%the swarm density (used to monitor environmental specification), maximum collision force experienced by agents, or the speed of all agents at a given time.

\paragraph*{[Q] Sensing and Metric Assumptions Log}

Much like the data log used within the traditional AMLAS framework, this log serves as a record of the details and decisions made in activities 6 and 7. This log should contain details of the choices made when producing the Test environment [N], Swarm Performance Metrics [M] and the Verification Metric [P].

\subsubsection*{Activity 8. Validate Evaluation Requirements}

Taking into account outputs [N], [O] and [P] from activity 7, this activity aims to validate these components with respect to the requirements specified in activity 6. Should any discrepancies exist between the data requirements and the evaluation requirements, they should be justified appropriately and recorded in output [S] Swarm Evaluation Validation Results.

\subsection{Stage 4: Model Emergent Behaviour} \label{framework-stage4}

% \noindent \textbf{\textit{[Lead:  WP5]}}\\ 
% \noindent\textbf{\textit{Author Guidelines: 900–1800 words / 1–2 pages (maximum); \\Format/structure: Describe adapted AMLAS activities, inputs and outputs using cloakroom case study examples. Activities: 10, 11; Inputs: H, N, O; Outputs: Candidate EB Algorithm, U, V, X}}\\\\
% See Fig.~\ref{amlas-a-stage4}

\begin{figure*}
	\centering
	\includegraphics[width=1.0\textwidth]{figures/amlas-a-stage4.png}
	\caption{Adapted AMLAS model learning process (right).}
	\label{amlas-a-stage4}
\end{figure*}

In the design of an emergent behaviour algorithm, the challenge is in selecting behaviours at the individual level of the agent which give rise to the desired emergent behaviour at the swarm level. The original AMLAS application in Stage 4 focused on the creation, testing and instantiation of a machine learning model for a single system with no emergent behaviours to consider for a collective. In our adaptation of AMLAS for the robot swarm,  we step away from the machine learning paradigm to allow consideration for all possible optimization algorithms which may attain the target emergent behaviour.

\subsubsection*{Activity 10. Create EB Algorithm:}

Here we have two levels to consider: the individual level behaviour which is informed by individual agent sensing capabilities [N*] and the swarm level emergent behaviour which shall necessarily meet the safety requirements [H] defined in Stage 2. In the example of the cloakroom given in Section \ref{ex:cloakroom}, the target emergent behaviour for the swarm shall ensure that items are stored and retrieved by individuals. Performance requirements RQ1.1 and RQ1.2 specify an upper bound on the low/high impact collisions that a swarm shall experience in a given time frame. These requirements may be fulfilled by constraining the maximum velocity of individual robots, for example, or by ensuring that a robot has a camera or infra-red sensors which enable it to detect obstacles. The outputs from this activity follow the AMLAS framework, with a candidate emergent behaviour algorithm produced rather than a ML model. Output [U], the model development log, should log the rationale in the design process of the emergent behaviour algorithm.

\subsubsection*{Activity 11. Test EB Algorithm:}

In this activity, the candidate emergent behaviour will be tested against the swarm performance metrics [O] produced in Stage 3. Testing ensures that the emergent behaviour performs as desired with respect to the defined metrics and in the case where performance is above the accepted thresholds, the emergent behaviour algorithm will be produced as an output [V] of the activity. The internal test results [X] will also be an output from the testing process.

\subsection{Stage 5: Model Verification} \label{framework-stage5}
\noindent \textbf{\textit{[Lead:  WP4]}}\\ 
\noindent\textbf{\textit{Author Guidelines: 900–1800 words / 1–2 pages (maximum); \\Format/structure: Describe adapted AMLAS activities, inputs and outputs using cloakroom case study examples. Activities: 13; Inputs: H, P, V; Outputs: Z, AA}}\\
See Fig.~\ref{amlas-a-stage5} and Fig.~\ref{amlas-a-testbench}.	

% *****************
% GC Contribution, see table for qualities on 'swarm' tab here:
% https://uob.sharepoint.com/:x:/r/teams/grp-TAS_Research2/Shared%20Documents/Verification/presentations/TrustQualities.xlsx?d=w4527b0bf0f4e49ab905d638dcb8c14ff&csf=1&web=1&e=8RW2vb

Inputs to the verification process are the [H] EB Safety Requirements, [P] Verification Scenarios (Test Generation) and [V] EB Algorithm. 
%
The verification method and assessment process within that method will be largely determined by the specifics of the safety requirements and examples from the cloakroom example will be used to illustrate the process. Some safety specifications lend themselves towards certain assessment methods due to the scenarios they prescribe.
%
For example, assessing the swarm system meets the requirements for performance given a motor fault injection [RQ1.6] may be easier to realise in physical or simulation based testing approaches, than constructing a reliable formal model of robot behaviour given the complex physical dynamics of a faulty wheel. 
%
However, when considering the adaptability requirements, a formal, probabilistic-based verification technique of the EB algorithm [V] is more suitable. For example, in [RQ2.1] analysis using a probabilistic finite state machine of the swarm behaviour tree, for example see \cite{Hoffmann2016,Calinescu2018}, could identify the dwell period within certain states. Monitors could be used to observe when agents enter a stationary state, e.g. \texttt{agent\_velocity=0 $\land $  t\_counter  $\ge$ 100}, and identify if time within that state exceeded some fixed value, and ascertain a probabilistic value to this metric.
%
These examples will now be expanded in more detail below.

\subsubsection{Verification Scenario (Test Generation) [P]}

In most cases there will be multiple, valid verification scenarios, also called test cases, applicable for each of the safety specifications. A `good test case' must be \emph{effective} at finding bugs or defects, \emph{efficient} in minimising the number of tests required, use resources \emph{economically} and be \emph{robust} to system changes~\cite{Fewster1999}. Using the EB Safety Requirements specification [H] and the principles of `good test cases', a few examples of potential scenarios and appropriate verification methods are explored in Table~\ref{tab:testgen}. 

For RQ1.1, relating to low impact collisions, suitable scenarios should consider a mix of both synthetic and physical testing to observe the safety compliance of the swarm controller. An important metric for assessing this safety requirement will be colllision detection which could be achieved either through on-board hardware sensors or indirectly through external monitoring, e.g. overhead camera and tracking system. Simulation is a valid verification method for RQ1.1 as testing time can be accelerated through parallelisation and test generation could be automated to include some randomisation and constrained randomisation whilst monitoring the collision detection metric. Physical testing, usually limited due to time and cost constraints, should be more prescriptive and should orchestrate scenarios that have a high probability of exercising the collision detection routine of the swarm agent controller, for example forcing swarm agents to travel a narrow passage to elevate sarm density. 

For simulation-based testing, a testbench can be used to orchestrate verification tasks, see Figure~\ref{amlas-a-testbench}. The testbench operates by using a \emph{simulator} to test the \emph{Agent Controller} software against \emph{Static} and \emph{Dynamic} stimuli. These stimuli are formed from \emph{Scenery} and \emph{Actor Behaviour} components which could be, for example, a virtual warehouse with staff, other robots and controllable lighting. The \emph{Swarm Requirements} are used to drive suitable experiment instantiation so that the stimuli provoke the intended behaviours in the swarm that will prove (or possibly disprove) the safety property for that experiment. A coverage monitor will be used to check that all the requirements have sufficient evidence against each entry, and for dynamic testbench architectures, cen even be used to drive additional test cases. 



\begin{figure*}
	\centering
	\includegraphics[width=1.0\textwidth]{figures/verification-testbench.png}
	\caption{Adapted AMLAS verification assurance process: test bench.}
	\label{amlas-a-testbench}
\end{figure*}

For RQ2.2, which ensures agents move every 100 seconds outside the delivery area, a suitable verification metric could monitor the time agents are ouside a designated geospatial area (the delivery site) in addition to monitoring agent wheel speed. Scenarios should be biased towards these conditions by, for example, ensuring a sufficient number of agents outside the delivery area (by making the delivery area small or non-existent) and monitoring when wheel speed is zero for sufficiently long horizons to improve the likelihood of witnessing such an event by chance. Increasing the chance that such rare events occur can accelerate evidence gathering which could be done in this case, for example, by constraining the agents environment, increasing swarm density, or fault injecting to the collision sensors so valid movement actions are limited. 

Whereas RQ1.1 is only suitable for simulation and physical testing, RQ2.2 could use these techniques in addition to also using a formal verification anlaysis. A formal analysis could take the form of a probabilistic finite stste machine [ref Radu], which would require a description of the agent states and the state transition proabilities. State transition probabilities can be derived from an action selection policy which, for this use case, can be derived from the swarm controller behaviour tree. Whereas testing based verification (physical, simulation, etc.) samples the input space, a formal analysis can prove a system property across the entire parameter range, which can be particularly beneficial in giving confidence in system compliance against the requirements. 


\begin{table*}[t]
\caption{Verification scenarios [P] and suitable methods.}\label{tab:testgen}
\centering
\begin{tabular}{llll}

\textbf{RQ}   & \textbf{Verification}  & \textbf{Verification} & \textbf{Scenario} \\ 
              & \textbf{Class}         & \textbf{Method}		  & 		          \\ 
\hline
1.1 	      & simulation 	   & constrained randomisation, directed tests & path intersection     \\
low impact    & physical testing   & prescriptive trial 				       & path intersection	 \\
collisions    & runtime		   & collision monitoring metric 		       & operational		 \\
\hline
2.2 	      & formal 	 	   & probabilistic finite state machine 	   & n/a      \\
movement      & simulation 	   & constrained randomisation, directed tests & task representative     \\
every 100s    & physical, runtime  & stationary monitoring metric 			   & operational		 \\
\hline
\end{tabular}
\end{table*}




Discuss swarm testbench...
Include agent-based test gen paper...
Option of 2D or 3D simulators...
Various methods within the verification class of simulation
Random, constrained random...
Assertion-based verification using simulation...
Simulation only needs to be "good enough" relative to the metric concerned [koopman]...

Physical testing offers the opportunity to measure ground-truth..
Resolves the reality-gap to simulation...
Physical tends to take longer, cost more to acquire data...

Runtime verification can offer a solution to verifying systems that operate in large state-spaces that may be intractable to verify at design time. However, the choice or design of runtime oracle [ref] which provides the ground truth may require significant development, or innovative solutions [cyres paper]. However, in this swarm case study this may be achieved with collision detection monitors, either implemented within the swarm robots or externally monitored through a tracking system, e.g. Vicon. Tracking with an external systems may be less reliable that physical sensing, e.g. accelerometer based collision detection, but being an independent system offers other assurances, as collisions may instigate cascading failure where the agents fail to report the collision event due to other failures, e.g. network connectivity.






\subsubsection{Verifiability}




\begin{itemize}
	\item Test bench for swarms
	\item Probabilistic verification ideas
	\item Simulation-based testing
	\item Verifiability?
\end{itemize}
\begin{figure*}
	\centering
	\includegraphics[width=1.0\textwidth]{figures/amlas-a-stage5.png}
	\caption{Adapted AMLAS verification assurance process (right).}
	\label{amlas-a-stage5}
\end{figure*}


\subsection{Stage 6: Model Deployment} \label{framework-stage6}
\noindent \textbf{\textit{[Leads:  WP4 \& WP5; Additional: WP3]}}\\ 
\noindent\textbf{\textit{Author Guidelines: 900–1800 words / 1–2 pages (maximum); \\Format/structure: Describe adapted AMLAS activities, inputs and outputs using cloakroom case study examples.\\ 
\noindent WP5 = (Activities: 15, Inputs: V, A, B, C, D, Outputs: DD), \\
\noindent WP4 = (Activities: 16, Inputs: EE, Outputs: FF), \\
\noindent WP3 = (Regulatory Considerations – 675 words / 0.75 page maximum)}}\\
See Fig.~\ref{amlas-a-stage6}
\begin{figure*}
	\centering
	\includegraphics[width=1.0\textwidth]{figures/amlas-a-stage6.png}
	\caption{Adapted AMLAS model deployment assurance process (right).}
	\label{amlas-a-stage6}
\end{figure*}

\subsubsection*{Activity 15. Integrate EB}

With the emergent behaviour verified, the next step is to take the model [V] as well as the system safety requirements [V], environment description [B] and system description [C] and integrate the emergent behaviour with the system to be deployed. In this activity we use the inputs to this stage to educate the implementation of the emergent behaviour and anticipate errors we might expect in the interactions between agents and the overall emergent behaviour. Despite the rigorous validation and testing conducted in previous stages, there will still be a gap between the test environment and the intended, every day use, deployed scenario. The output, [DD] Model Development Log, captures these anticipated gaps between testing and reality and the differences in behaviour that might sprout from them.

For example, once physically deployed it may become apparent that large fluctuations in speed used to maintain performance while keeping the system safe for Humans, may in reality be too much of a draw on the agents batteries to get a reasonable lifetime out of each battery charge. To address this the behaviour may need to be tweaked to sacrifice some performance in the short term, reducing the rates of acceleration experienced by agents, in order to gain a longer battery life.

\subsubsection*{Activity 16. Test the Integration}

Once the initial integration is complete the physical implementation should undergo an additional round of testing in which the system will be observed in multiple operational scenarios, as specified in [EE].

\paragraph*{[EE] Operational Scenarios}

These operational scenarios should reflect the environment descriptions specified in [B], offering a real-world situations to examine the behaviour of the integrated system. The testing of the integrated system in these true-to-operation environments should be conducted in a safe manner. Ensuring that the entire multi-agent system can be shut down in an emergency, or providing shadow operators for groups of agents, taking over should the swarm behave erroneously.

In our cloakroom scenario, an example of [EE] may take the form of a small deployment of agents in a real but controlled coat storage area.

% Capture any integration issues

% provide a few environment examples

% Identify Erroneous behaviour expected and outlined in [DD], while simultaniously looking to catch/identify any issues of integration previously overlooked.

\paragraph*{[FF] Integration Testing Results}

Results from the integration testing will be reported here, detailing how the system performs against the safety requirements [H] specified in stage 2.

%\subsection{Stage 7: Assurance Case}
	
\section{Discussion and Conclusions} \label{discussion-conclusions}

\section*{Acknowledgments}
The work presented in this paper has been supported by the UK Engineering and Physical Sciences Research Council (EPSRC) under the grant [EP/V026518/1].

{\appendices
\section*{Appendix A. Supplementary Material}
The supplementary material associated with this article can be found online at (https://www.).


\bibliographystyle{IEEEtran}
\bibliography{AssuranceFWK-Swarms-Bibliography}

\newpage

\vfill

\end{document}


